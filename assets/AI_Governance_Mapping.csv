Descriptive,,,,,,,,,Scoring (Toy Model),,,,,,,,
Category,Idea,Description,Examples,Literature examples,Scope (Global vs. National),Failure modes,Closest current/ historical equivalent,Current progress,Verifiability,Institutional Fit (China US),Capacity Load (reverse-scored),Evasion Resistance,Scalability (to different countries),Political Ease of implementation,Impact if successful,Impact Rating,Notes on ratings
1. Strategic Postures (macro-orientation),Laissez-faire ,"Let models proliferate, no global action.",Permissionless Innovation,https://www.civitasinstitute.org/research/defending-technological-dynamism-the-freedom-to-innovate-in-the-age-of-ai,Other,Runaway proliferation of unsafe models; tragedy-of-the-commons dynamic.,Early internet policy (“permissionless innovation” in the 1990s).,Still the de facto baseline in most jurisdictions.,0,3,3,1,1,3,0.5,5.5,
1. Strategic Postures (macro-orientation),AI clubs / blocs,Developing networks between aligned countries for AI coordination,G7 Hiroshima Process,https://www.oecd.org/content/dam/oecd/en/publications/reports/2023/09/g7-hiroshima-process-on-generative-artificial-intelligence-ai_8d19e746/bf3c0c60-en.pdf ,Global,"Fragmentation; blocs undercut each other; excludes key players (China, India, Russia).","G7, NATO, or nuclear clubs (non-proliferation treaty’s “nuclear weapon states”).",G7 Hiroshima Process; OECD-led frameworks.,1.5,2,2,2,2,2,1,11.5,
1. Strategic Postures (macro-orientation),Open Global Investment (OGI),Use market-based mechanisms to concentrate investment in certain actors,OGI (Bostrom),https://www.lesswrong.com/posts/LtT24cCAazQp4NYc5/open-global-investment-as-a-governance-model-for-agi,National,Capture by host state; investors lack credible protection; geopolitical rivals reject neutrality.,Multinational corporate structures in oil/telecoms,"Exists as a thought experiment (Bostrom), no state backing.",1,1.5,2,1,1.5,2.5,1.5,14.25,
1. Strategic Postures (macro-orientation),MAD/MAIM (Mutually-Assured Destruction/AI Malfunction),Deterrence-based equilibrium,Superintelligence Strategy,https://arxiv.org/abs/2503.05628 ; https://www.nationalsecurity.ai/chapter/deterrence-with-mutual-assured-ai-malfunction-maim,Global,Misperception of capabilities; accidental escalation; deterrence fails under uncertainty.,Cold War nuclear deterrence (MAD).,Early academic discussion; no formal adoption but present in policy rhetoric.,0,3,2,2,1,1.5,1.5,14.25,
1. Strategic Postures (macro-orientation),Global Moratorium,Halt AGI development,"A Narrow Path, MIRI",https://moratorium.ai/ ; narrowpath.co,Global,Quiet defection; enforcement impossible; moratorium breaks down in conflict,Nuclear Test Ban Treaty attempts; biological research moratoria.,"Normative advocacy (moratorium.ai, MIRI; narrow path); no policy uptake.",1,1,0,1,2,0,3,15,
1. Strategic Postures (macro-orientation),Cooperative development,International laws ensure defensive AI technologies aligned with humans are developed before offensive technologies,"Success without dignity (HK), Anthropic (Checklist), D/Acc (Vitalik)",https://www.lesswrong.com/posts/jwhcXmigv2LTrbBiB/success-without-dignity-a-nearcasting-story-of-avoiding ; https://arxiv.org/abs/2310.09217,Global,Defection (states run secret projects); verification gaps; politicised stalemate.,CERN; ITER nuclear fusion collaboration.,"Limited rhetorical support (Anthropic checklist, “Success without dignity”), no binding deals.",1.5,1,2,1,2,1,2,17,
1. Strategic Postures (macro-orientation),D/Acc (Defensive Accleration),Differentially develop decentralised defensive capabilities before offensive capabilities emerge,D/Acc (Vitalik),https://80000hours.org/podcast/episodes/vitalik-buterin-techno-optimism,Multiple,Offensive work disguised as defensive; incentives skew toward dual-use; decentralisation increases attack surface,Decentralised cryptography; cyber “bug bounty” culture.,"Popular among some technologists (Buterin), not institutionalised.",1,2,2,2,2,3,1.5,18,
1. Strategic Postures (macro-orientation),Non-proliferation,"Stop proliferation of AI capabilities, prevent diffusion of dangerous models or capabilities",Superintelligence Strategy,https://www.nationalsecurity.ai/chapter/nonproliferation ,Global,"Leakage via open weights, smuggling, or “rogue” states; dual-use ambiguity.",Nuclear Non-Proliferation Treaty (NPT); WMD export controls.,Actively pursued via US/EU export controls and licensing proposals.,2,2,2,2,2,2,1.5,18,
1. Strategic Postures (macro-orientation),Strategic advantage,"Make sure one actor ""wins"", by developing advanced AI systems faster than geopolitical rivals",Heritage Foundation,https://www.nationalsecurity.ai; https://www.heritage.org/big-tech/commentary/the-us-not-china-should-take-the-lead-ai ; https://arxiv.org/html/2507.06379,Global,Security dilemma spiral (https://en.wikipedia.org/wiki/Security_dilemma); racing undermines safety; escalation risk.,Early cold war; space race.,"Current US dominance, enforced through chip superiority",1,3,2,2,1,3,1.5,18,
2. Institutional Architectures,Self-governance ,Firms introducing voluntary standards for AGI governance,"Permissionless Innovation, D/Acc (Vitalik), G7 Hiroshima Process",https://www.lesswrong.com/posts/B2DFgzG6bptZvin9L/examples-of-self-governance-to-reduce-technology-risk,Lab-based,Weak incentives; PR without substance; unilateral defection.,Early biotech self-regulation (Asilomar Conference on Recombinant DNA (1975)).,"Frontier Safety Frameworks (voluntary pledges, 2024 Seoul).",1,3,3,0,2,3,0.5,6,
2. Institutional Architectures,Institution for distribution of benefits & access,"Institutions for distributing the benefits of AI. or access to transformative AI systems, to all parties to an agreement. ",Windfall clause (Bostrom),https://cdn.governance.ai/Options_and_Motivations_for_International_AI_Benefit_Sharing.pdf ; https://www.governance.ai/research-paper/the-windfall-clause-distributing-the-benefits-of-ai-for-the-common-good ; https://www.convergenceanalysis.org/fellowships/spar-economics/lead-own-share-sovereign-wealth-funds-for-transformative-ai,Multiple,"States defect, hoard benefits; disputes over allocation; unenforceable; doesn't address misalignment risk",Windfall Clause proposals; UN development funds.,"Mostly academic/EA/LW based (Bostrom, GovAI); no implementation.",1.5,1,1.5,1,1.5,1,1.5,11.25,
2. Institutional Architectures,Corporate governance bodies,Board-level structures for AI risk (enforced or encouraged),"A Narrow Path, OGI (Bostrom), Permissionless Innovation, Responsible scaling policies, Frontier Safety Frameworks",https://www.lesswrong.com/posts/KD4AMfaF3eeWdQwAC/corporate-governance-for-frontier-ai-labs-a-research-agenda,National,Board capture; lack of true alignment (box-ticking committees); incentives skew to profit.,Sarbanes–Oxley compliance boards (https://en.wikipedia.org/wiki/Sarbanes–Oxley_Act); ESG mandates.,"Early discussion in UK, Anthropic “responsible scaling policies”.",1.5,1.5,3,1.5,1.5,2.5,1,11.5,
2. Institutional Architectures,Enforcement of standards/restrictions (International AI Safety Agency),Regulatory global agency with international buy-in,A Narrow Path,https://academic.oup.com/ia/article/101/4/1483/8141294 ; https://arxiv.org/abs/2310.09217,Global,"Non-compliance, sovereignty objections, weak enforcement powers",IAEA; OPCW (chemical weapons).,"Purely theoretical; referenced in Narrow Path, GovAI writing.",1.5,0.5,0.5,1,2,1,2,13,
2. Institutional Architectures,Scientific consensus building organisations (IPCC-for-AI),International scientific consensus body,"Seoul (plus), GAIO (Carnegie)",https://carnegiecouncil.org/media/article/the-case-for-a-global-ai-observatory-gaio-2023,Global,Politicisation of reports; delays between science and policy uptake; expert capture.,IPCC (Intergovernmental Panel on Climate Change),"GAIO proposal (Carnegie), Seoul AI Summit language.",2,2.5,2.5,3,3,2.5,1,15.5,
2. Institutional Architectures,Political forum (UNFCCC-style),Ongoing norm-setting and review cycles,"Global AI Governance Initiative & Action Plan, G7 Hiroshima Process, UN Framework Convention on AI (UNFCAI)",https://www.fmprc.gov.cn/eng./xw/zyxw/202507/t20250729_11679232.html; https://en.wikipedia.org/wiki/Global_Partnership_on_Artificial_Intelligence ; ,Global,Pledges without compliance; free-riding; delay tactics,UNFCCC; Convention on Biological Diversity.,Early talks on “UNFCAI”; China floated recent proposals at UN.,1.5,2,2.5,1,2,2,1.5,16.5,
2. Institutional Architectures,Emergency response & stabilization hub,"Rapid, cross-jurisdiction incident response (IAEA Incident Centre analogue)",Geotechnology stability board,https://www.eurasiagroup.net/files/upload/GovernanceRegimes.pdf,Global,Delayed reporting; lack of jurisdiction; major powers defect in a crisis; too late to avert misalignement scenario,IAEA Incident Centre; WHO pandemic alert systems.,"Only in think tank reports (Eurasia Group), not yet piloted.",2,2,1.5,1.5,2.5,2,1.5,17.25,
2. Institutional Architectures,Independent national regulator,"Establish independent regulator to regulate, monitor and audit AI companies and models",A Narrow Path,narrowpath.co,National,Lack of independence (esp. authoritarian contexts); risk of capture; duplication with existing agencies.,UK Ofcom; ,"Proposed in Narrow Path; UK flirted with idea, but most countries embedding into existing regulators.",2.5,0.5,2,2,1.5,1.5,2,20,
2. Institutional Architectures,Coordination of policy & regulation,"Coordination layer for eval methods, red-team playbooks, and info-sharing","INAISI (Network of AISIs), Global AI Governance Initiative & Action Plan",https://www.nist.gov/system/files/documents/2024/11/20/Mission%20Statement%20-%20International%20Network%20of%20AISIs.pdf ; https://www.csis.org/analysis/ai-safety-institute-international-network-next-steps-and-recommendations,Global,Shallow harmonisation (lowest common denominator); non-binding guidance ignored.,Financial Stability Board; OECD guidelines.,"Ongoing via G7 Hiroshima Process, INAISE, Global AI Governance Initiative.",2,2.5,2,2,3,2,1.5,20.25,
2. Institutional Architectures,Domestic AI regulators (existing),National-level agencies,"EU AI Act, Chinese CAC Interim measures",https://arxiv.org/html/2507.06379,National,"Patchwork rules, regulatory arbitrage; under-resourced.",US FTC; EU telecom regulators; China’s CAC.,"EU AI Act (national agencies), China’s CAC interim rules, UK multi-regulator taskforce.",2,3,2.5,2,2,2.5,1.5,21,
2. Institutional Architectures,International Joint Research (CERN for AI),"Joint, multipolar development organisation for AGI",A Narrow Path,https://hai.stanford.edu/white-paper-enhancing-international-cooperation-ai-research-case-multilateral-ai-research-institute,Global,Geopolitical exclusion (US/China rivalry); governance capture by host state; risk of dual-use leakage.,CERN; ITER (International Thermonuclear Experimental Reactor) nuclear fusion project.,"Appears in policy papers (Stanford HAI, Narrow Path), no formal commitment.",3,2,1,2,2,1.5,2,23,
2. Institutional Architectures,Embedding in existing institutions,"Using existing institutions for AI governance - ""bolt on"" additional provisions",IEC/ISO Working Group,https://www.iso.org/technical-committees.html,Multiple,Mandates diluted; existing institutions lack teeth; some institutions lack expertise and competence.,WTO “bolt-on” clauses; ISO/IEC standards.,"Already happening (ISO/IEC committees, G7 Hiroshima Process).",2,3,3,2,3,3,1.5,24,
3. Regulatory/Legal Mechanisms,Auditor certification regimes,Certification schemes to train and verify auditing bodies,EU AI Act,https://cloudsecurityalliance.org/blog/2025/05/08/iso-42001-lessons-learned-from-auditing-and-implementing-the-framework,Global,Auditor capture; weak oversight; cross-border credential misalignment,Financial audit firms (Big Four); ISO 27001 auditors.,EU AI Act sketches auditor role; industry coalitions (Cloud Security Alliance).,3,2,2,2.5,3,2,1,14.5,
3. Regulatory/Legal Mechanisms,Liability-based mechanisms,Civil or criminal responsibiliity for certain acts,EU Product Liability Directive,https://www.rand.org/pubs/research_reports/RRA3243-4.html ; https://www.europarl.europa.eu/RegData/etudes/BRIE/2023/739341/EPRS_BRI(2023)739341_EN.pdf,National,Weak courts in non-democratic states; long lag between harm and judgment,Product liability law; tobacco litigation.,EU revised product liability directives; US FTC exploring liability angles.,2,0.5,2,2,2.5,1.5,1.5,15.75,
3. Regulatory/Legal Mechanisms,Whistleblower protections,Instituting protections at a domestic level for whistleblowers at AI labs or other AI infrastructure organisations,"Right To Warn, EU AI Act",https://righttowarn.ai/ ; https://thefuturesociety.org/ai-whistleblowers,Multiple,Weak enforcement in authoritarian systems; only effective if whistleblowers emerge at the right time,"US/UK whistleblower laws (Sarbanes–Oxley, SEC).",RightToWarn initiative; EU AI Act mentions; negligible outside democracies.,2,0.5,2.5,2.5,1.5,1.5,1.5,15.75,
3. Regulatory/Legal Mechanisms,Market-shaping mechanisms,Use mechanisms like prizes and advance market commitments to incentivize broad dissemination of products and safety features ,Windfall clause (Bostrom),https://www.ucl.ac.uk/bartlett/public-purpose/publications/2023/jan/collective-response-our-global-challenges-common-good-and-market-shaping ; https://arxiv.org/html/2507.06379,Multiple,Subsidy gaming; misallocation; firms get benefits without safety improvements; not comprehensive enough.,AMCs for vaccines; clean-tech subsidies.,Discussed in policy papers; some funding for AI safety research but no global mechanism.,1,2.5,2,1.5,2,2,1.5,16.5,
3. Regulatory/Legal Mechanisms,Frontier Safety Frameworks,Frontier labs pledge voluntary to abide by certain safety principles,"Frontier Safety Frameworks, Seoul (plus)",https://www.gov.uk/government/publications/frontier-ai-safety-commitments-ai-seoul-summit-2024/frontier-ai-safety-commitments-ai-seoul-summit-2024,Lab-based,Box-ticking; vague commitments; labs defect if costly.,Responsible Care (chemicals industry pledges).,"Voluntary pledges at 2023–24 AI Summits (UK, Seoul).",2,1.5,2,2,2,2,1.5,17.25,
3. Regulatory/Legal Mechanisms,Pre-deployment evaluation,"Safety tests, evaluations, red-teaming","Frontier Safety Frameworks, EU AI Act, A Narrow Path",https://www.mofa.go.jp/files/100573473.pdf ,Lab-based,Firms stage-manage tests; benchmarks lag capabilities; red-teaming becomes perfunctory.,FDA drug trials; product safety testing.,"Referenced in EU AI Act, US voluntary commitments, Anthropic RSPs.",2,2,2,2,2,2,1.5,18,
3. Regulatory/Legal Mechanisms,Mandatory transparency reports,Labs are obliged to submit reports to a national or international body,EU AI Act,https://futurium.ec.europa.eu/pt/european-ai-alliance/document/navigating-article-5-eu-ai-act-what-enterprises-need-know,Multiple,Firms can deceive or hide information; information overload; regulators might struggle to process data.,Environmental reporting mandates.,EU AI Act requires transparency filings; some US proposals.,2.5,2,2.5,1.5,2.5,2.5,1.5,20.25,
3. Regulatory/Legal Mechanisms,Sector-specific prohibitions,"Limiting use of AI in biotech, military etc.","Stop Killer Robots, EU AI Act",https://www.stopkillerrobots.org/,Multiple,Dual-use ambiguity; firms relabel use cases; enforcement leaks to illicit markets.,Bioweapons bans; “Stop Killer Robots” advocacy.,EU AI Act includes high-risk domain prohibitions; NGO campaigns ongoing.,2,3,2.5,1.5,2.5,2,1.5,20.25,
3. Regulatory/Legal Mechanisms,Incident reporting registry,Shared error disclosure,"EU AI Act, G7 Hiroshima Process",https://www.oecd.org/content/dam/oecd/en/publications/reports/2025/02/towards-a-common-reporting-framework-for-ai-incidents_8c488fdb/f326d4ac-en.pdf,Global,Under-reporting; fear of liability; firms classify incidents away.,Aviation safety reporting systems; cybersecurity breach notifications; IAEA,OECD and EU working on harmonised incident reporting; early draft frameworks.,2,2.5,3,1.5,3,2.5,1.5,21.75,
3. Regulatory/Legal Mechanisms,Model registry,Registering models/use-cases,EU AI Act,https://artificialintelligenceact.eu/article/49/ ; https://www.convergenceanalysis.org/research/ai-model-registries-a-foundational-tool-for-ai-governance,Multiple,Non-compliance (secret models); skirting around definitions of overly large or dangerous models,Chemical inventories; aircraft registries.,EU AI Act Article 49; convergenceanalysis.org proposals.,2.5,3,2.5,1.5,3,2.5,1.5,22.5,
3. Regulatory/Legal Mechanisms,Standard Setting,Voluntary norms to encourage standards,"G7 Hiroshima Process, IEC/ISO Working Group",https://www.iso.org/committee/6794475.html ; https://cloudsecurityalliance.org/blog/2025/05/08/iso-42001-lessons-learned-from-auditing-and-implementing-the-framework,Multiple,Weak uptake if voluntary; divergence across jurisdictions; industry capture of committees.,"ISO, IEC, W3C standards.","ISO/IEC AI committees, G7 Hiroshima guidelines, ISO 42001 standard.",1.5,3,3,1.5,3,3,1.5,22.5,
3. Regulatory/Legal Mechanisms,Staged capability thresholds,Agree to pause or tighten rules at specific capability milestones,A Narrow Path,https://law-ai.org/the-role-of-compute-thresholds-for-ai-governance/,Multiple,Thresholds gamed; incentives to underestimate capabilities; uneven adoption.,Arms-control treaties tied to missile counts; Basel banking accords.,"Increasing traction (compute thresholds in Narrow Path, EU AI Act debate",2,2,2,2,2,2,2,24,
3. Regulatory/Legal Mechanisms,Licensing,"Approvals for models based on certain requirements, such as compute thresholds or capability tests",A Narrow Path,https://data.consilium.europa.eu/doc/document/ST-5662-2024-INIT/en/pdf,Multiple,Shadow labs operate unlicensed; capture by dominant firms; uneven enforcement.,Aviation licences; nuclear plant licensing.,EU AI Act prototypes; China’s CAC licensing regime.,2,2.5,2,2,2,2,2,25,
4. Technical & Infrastructural Controls,Energy/Power-use monitoring,Using monitoring of utilities to observe high power usage associated with GPU use,Compute at Scale (Pilz and Heim),https://arxiv.org/abs/2311.02651,Multiple,False metering; signal not specific to AI training.,Industrial power audits; cryptocurrency mining crackdowns.,Proposed in Heim & Pilz “Compute at Scale”; some Chinese provinces already monitoring power anomalies.,2,2,2,1.5,2,2,1,11.5,
4. Technical & Infrastructural Controls,Kill-switch protocols,Technical mechanisms to enable emergency suspension of a training run or inference process,"EU AI Act, Frontier Safety Frameworks",https://www.lesswrong.com/posts/pvfr5FqcnA7txDPZm/non-technical-strategies-for-confronting-a-human-level-ai,Multiple,Developers disable or fake compliance; accidental triggers; politically unacceptable to mandate.,Nuclear “permissive action links”; emergency stop systems in aviation.,"Mostly conceptual; some mention in EU AI Act and safety pledges, no technical standards.",2,1,1.5,1.5,1,1,2,16,
4. Technical & Infrastructural Controls,Export controls,"Limiting the export of chips, compute or talent","CHIPS Act, Gov.AI (various), Rand",https://www.lesswrong.com/posts/BkzeJZCuCyrQrEMAi/dario-amodei-on-deepseek-and-export-controls,National,"Smuggling, grey markets, re-export via intermediaries; incentives for indigenous capability.","Nuclear dual-use export controls; semiconductor sanctions (COCOM, Wassenaar).",Active: US/EU/Japan controls on advanced GPUs; China imposing talent outflow restrictions.,2.5,3,2,2.5,2,2,1.5,21,
4. Technical & Infrastructural Controls,Hardware-based verification,On-chip mechanisms to stop misuse or use that contravenes a limitation,"A Narrow Path, Rand, Gov.AI (various), Heritage Foundation",https://arxiv.org/html/2505.03742v1,National,Circumvention by modifying firmware; compromised fabs; jurisdictional divergence in standards.,Trusted Platform Modules (TPMs); Digital Rights Management (DRM) enforcement; IMEI device tracking.,Early discussion in RAND/GovAI papers; chipmakers experimenting with secure enclaves.,3,2,2,2.5,2,1.5,2,26,
4. Technical & Infrastructural Controls,Cloud-based enforcement,Using cloud-based mechanisms to stop access to certain hardware or processes (e.g. model training or inference),Gov.AI (various),https://cdn.governance.ai/Governing-Through-the-Cloud_The-Intermediary-Role-of-Compute-Providers-in-AI-Regulation.pdf,National,Regulatory arbitrage (training outside covered providers); false reporting; privacy pushback.,Financial KYC (Know-Your-Customer) requirements enforced through banks; App Store gatekeeping.,"Momentum growing: US, UK, GovAI papers on “Governing through the Cloud”; pilots for compute usage logging.",3,2,2,2,2.5,2,2,27,
4. Technical & Infrastructural Controls,Technical compute caps,Using physical limits on chips or architectures so that models can't be built over a certain size,MIRI,https://arxiv.org/abs/2503.04746,Multiple,Workarounds via distributed training; new algorithms achieve more with less compute; enforcement costly.,OPEC production quotas; emissions caps; bandwidth throttling.,"Proposed by MIRI and others; not implemented, but compute thresholds discussed in AI Act drafts and Narrow Path.",2.5,2,2,1.5,2.5,1.5,2.5,30,
4. Technical & Infrastructural Controls,Software-based verification,"Monitors training processes or inference hrough cryptography, proof-of-learning etc.",D/Acc (Vitalik),https://futureoflife.org/ai/verifiable-training-of-ai-models/ ; https://arxiv.org/pdf/2506.23706,Multiple,Evasion through modified software stacks; log forgery or selective disclosure; slow adoption; regulators unable to interpret or act on logs,Blockchain attestations; software license verification; reproducible clinical trials; financial transaction audit trails.,Conceptual stage in governance papers; some prototypes (AI “passports”); not yet standardised.,2.5,2,2,1.5,2,1.5,2,23,